{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8c98278-a118-4b66-8930-8508803714b4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sc = SparkSession.builder.appName('Ops').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54156fa2-b9cb-4976-bd9c-d60aa1803c9d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as f\n\ntrials = spark.read.options(delimiter = \"|\", header = True, inferSchema = True).csv(\"/FileStore/tables/clinicaltrial_2021.csv\")\n\npharm = spark.read.options(escape = \"\\\"\", header = True, inferSchema = True).csv(\"/FileStore/tables/pharma.csv\")\n\nmesh = spark.read.options(escape = \"\\\"\", header = True, inferSchema = True).csv(\"/FileStore/tables/mesh.csv\").withColumn(\"code\", f.split(f.col(\"tree\"), \"\\.\")[0]).withColumn(\"term\", f.trim(\"term\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afd5dc70-aa56-45ad-a97c-ca475bbee497"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Problem 1 = \"The number of studies in the dataset. You must ensure that you explicitly check distinct studies.\"\ntrials.select('Id').distinct().count() "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aae04728-bf90-49a6-9964-d0e01f986c4f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: 387261","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: 387261"]}}],"execution_count":0},{"cell_type":"code","source":["#Problem 2 = \"You should list all the types (as contained in the Type column) of studies in the dataset along with the frequencies of each type. These should be ordered from most frequent to least frequent.\"\ntrials.dropna(subset = \"Type\").groupBy(\"Type\").count().orderBy(\"count\", ascending = False).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3975962d-78c0-405a-8720-5c7edb28ca49"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+------+\n|                Type| count|\n+--------------------+------+\n|      Interventional|301472|\n|       Observational| 77540|\n|Observational [Pa...|  8180|\n|     Expanded Access|    69|\n+--------------------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+------+\n|                Type| count|\n+--------------------+------+\n|      Interventional|301472|\n|       Observational| 77540|\n|Observational [Pa...|  8180|\n|     Expanded Access|    69|\n+--------------------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Problem 3 = \"The top 5 conditions (from Conditions) with their frequencies.\"\nconds = trials.select('Conditions').dropna(subset = \"Conditions\").withColumn(\"temp cond\", f.explode(f.split(f.col(\"Conditions\"), \",\"))).groupBy(f.trim(\"temp cond\").alias(\"Conditions\")).count().orderBy(\"count\", ascending = False)\n\nconds.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"538fe2ad-8d2c-41f6-b4c5-5bb492fcc1ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------+-----+\n|       Conditions|count|\n+-----------------+-----+\n|        Carcinoma|13389|\n|Diabetes Mellitus|11080|\n|        Neoplasms| 9371|\n| Breast Neoplasms| 8640|\n|         Syndrome| 8032|\n+-----------------+-----+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------+-----+\n|       Conditions|count|\n+-----------------+-----+\n|        Carcinoma|13389|\n|Diabetes Mellitus|11080|\n|        Neoplasms| 9371|\n| Breast Neoplasms| 8640|\n|         Syndrome| 8032|\n+-----------------+-----+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Problem 4 = \"Each condition can be mapped to one or more hierarchy codes. The client wishes to know the 5 most frequent roots (i.e. the sequence of letters and numbers before the first full stop) after this is done.\"\nconds.join(mesh, f.col(\"Conditions\") == f.col(\"term\"), \"left\").groupBy(\"code\").sum(\"count\").orderBy(\"sum(count)\", ascending = False).show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2fb6616-e534-4116-b6cb-77d0bb9829be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+----------+\n|code|sum(count)|\n+----+----------+\n| C04|    143994|\n| C23|    136079|\n| C01|    106674|\n| C14|     94523|\n| C10|     92310|\n+----+----------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+----------+\n|code|sum(count)|\n+----+----------+\n| C04|    143994|\n| C23|    136079|\n| C01|    106674|\n| C14|     94523|\n| C10|     92310|\n+----+----------+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Problem 5 = \"Find the 10 most common sponsors that are not pharmaceutical companies, along with the number of clinical trials they have sponsored. Hint: For a basic implementation, you can assume that the Parent Company column contains all possible pharmaceutical companies.\" \ncurrentpharm = [row['Parent_Company'] for row in pharm.select(\"Parent_Company\").distinct().collect()]\n\ntrials.filter(~f.col('Sponsor').isin(currentpharm)).groupBy(f.col(\"Sponsor\")).count().orderBy(\"count\", ascending = False).show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb55d5dd-f55b-4f56-bd6a-9d3a5820a78e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+-----+\n|             Sponsor|count|\n+--------------------+-----+\n|National Cancer I...| 3218|\n|M.D. Anderson Can...| 2414|\n|Assistance Publiq...| 2369|\n|         Mayo Clinic| 2300|\n|Merck Sharp & Doh...| 2243|\n|   Assiut University| 2154|\n|Novartis Pharmace...| 2088|\n|Massachusetts Gen...| 1971|\n|    Cairo University| 1928|\n|   Hoffmann-La Roche| 1828|\n+--------------------+-----+\nonly showing top 10 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+-----+\n|             Sponsor|count|\n+--------------------+-----+\n|National Cancer I...| 3218|\n|M.D. Anderson Can...| 2414|\n|Assistance Publiq...| 2369|\n|         Mayo Clinic| 2300|\n|Merck Sharp & Doh...| 2243|\n|   Assiut University| 2154|\n|Novartis Pharmace...| 2088|\n|Massachusetts Gen...| 1971|\n|    Cairo University| 1928|\n|   Hoffmann-La Roche| 1828|\n+--------------------+-----+\nonly showing top 10 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Problem 6 = \"Plot number of completed studies each month in a given year â€“ for the submission dataset, the year is 2021. You need to include your visualization as well as a table of all the values you have plotted for each month\"\n\ntrials.filter((f.col(\"Status\") == 'Completed') & (f.split(f.col(\"Completion\"), \" \")[1] == '2021')).groupBy(f.col(\"Completion\")).count().orderBy(\"count\", ascending = False).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73e33678-a229-4336-a49c-0206fe719726"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+-----+\n|Completion|count|\n+----------+-----+\n|  Mar 2021| 1227|\n|  Jan 2021| 1131|\n|  Jun 2021| 1094|\n|  May 2021|  984|\n|  Apr 2021|  967|\n|  Feb 2021|  934|\n|  Jul 2021|  819|\n|  Aug 2021|  700|\n|  Sep 2021|  528|\n|  Oct 2021|  187|\n+----------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-----+\n|Completion|count|\n+----------+-----+\n|  Mar 2021| 1227|\n|  Jan 2021| 1131|\n|  Jun 2021| 1094|\n|  May 2021|  984|\n|  Apr 2021|  967|\n|  Feb 2021|  934|\n|  Jul 2021|  819|\n|  Aug 2021|  700|\n|  Sep 2021|  528|\n|  Oct 2021|  187|\n+----------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee5cda41-c1a8-46f1-9b2e-9e6a513fa4d8"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"AWS Version","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2964162248036564}},"nbformat":4,"nbformat_minor":0}
